The model(XGBClassifier) achieved an accuracy of 76%
<img width="950" height="661" alt="image" src="https://github.com/user-attachments/assets/8377f5d0-be9d-474a-8c16-9f85063e19cf" />
XGBoost was chosen by me
It handles large datasets well.
It captures non-linear relationships more effectively.
It gave better precision/recall tradeoffs overall, especially visible in the classification report.
TF-IDF (Term Frequencyâ€“Inverse Document Frequency), Focus more on rare but meaningful words.
Challenges faced:
In Data Cleaning(Which is the first time to clean this kind of data)
